{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some iron ore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "seaborn.set()\n",
    "\n",
    "df = pandas.read_csv(os.path.abspath('iron_ore_study.csv'))\n",
    "\n",
    "# Splits from oscar Fe>60%, SiO2<9, Al2O3<2, P<0.08\n",
    "split_points = [\n",
    "    ('FE', 60, [False, True]),\n",
    "    ('SIO2', 9, [True, False]),\n",
    "    ('AL2O3', 2, [True, False]),\n",
    "    ('P', 0.08, [True, False]),  \n",
    "]\n",
    "\n",
    "# It's ore if everything is True\n",
    "df['is_ore'] = np.vstack([\n",
    "    pandas.cut(df[elem], bins=[0, split, 100], labels=is_ore)\n",
    "    for elem, split, is_ore in split_points\n",
    "]).sum(axis=0) == 4\n",
    "\n",
    "# Take a look\n",
    "seaborn.pairplot(df.iloc[::5], hue='is_ore', plot_kws={'alpha': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.countplot('is_ore', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot our x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.jointplot('SIO2', 'FE', df, joint_kws={'alpha': 0.4, 'marker': '.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.jointplot('P', 'FE', df, joint_kws={'alpha': 0.4, 'marker': '.'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "You can think of the logistic function as a function that takes a real number (as comes out of the linear regression) and 'squashes' it into a 0, 1 label. It's defined as\n",
    "\n",
    "$$\n",
    "g(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):    \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "zs = np.linspace(-10, 10)\n",
    "logistic_data = pandas.DataFrame( \n",
    "    {'z': zs, 'logistic': logistic(zs)}\n",
    ")\n",
    "logistic_data.plot('z', 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can generate a linear model fit with one parameter - call it $f$:\n",
    "\n",
    "$$\n",
    "z = f(x) = a + b x\n",
    "$$\n",
    "\n",
    "where $a$ is the intercept, $b$ the coefficient and $x$ is the input features. Then we get label predictions\n",
    "\n",
    "$$\n",
    "\\mathrm{label} = g(f(x)) > threshold\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Let's pretend we have a crappy sensor which only measures Al. Can we still make good predictions of ore/not ore using just this feature?\n",
    "\n",
    "We should look at transforming our aluminium data so that we go from (0, inf) -> (-inf, inf). We'll do this in a hacky sense by using a log function but we should really use a log-ratio transform here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(df['AL2O3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(np.log(df['AL2O3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do this using a scikit-learn pipeline - this lets us chain transformations and predictions into one object which makes life a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, pipeline, linear_model\n",
    "\n",
    "# Make up our pipeline where we transform the aluminium first to make it more gaussian!\n",
    "regressor = pipeline.Pipeline([\n",
    "    ('transform', preprocessing.FunctionTransformer(np.log, validate=True)),\n",
    "    ('model', linear_model.LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we map the data into the `y ~ f(X)` format that scikit-learn wants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['AL2O3']]\n",
    "y = df['is_ore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fitting the model is as simple as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've fitted the model we can make predictions straight away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pandas.DataFrame(\n",
    "    {'test_al2o3_values': [0.5, 1, 2, 3, 4]} # Are these values ore?\n",
    ")  \n",
    "regressor.predict(predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what's going on in a bit more depth, we can pull the coefficients out of the scikit-learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regressor.named_steps.model\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and rewrite our logistic function to include the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(regressor, X):\n",
    "    \"\"\"\n",
    "    Plot our logistic model given input values x\n",
    "    \n",
    "    We're doing this so that we can see the output of the logistic function - normally\n",
    "    you'd just do `regressor.predict(x)` to get actual 1, 0 labels for your data.\n",
    "    \n",
    "    Parameters:\n",
    "        regressor - a fitted logistic regression pipeline\n",
    "        x - the values to evaulate the function at\n",
    "    \"\"\"\n",
    "    # We can pull the model and transforms from our pipeline\n",
    "    model = regressor.named_steps.model\n",
    "    tf = regressor.named_steps.transform\n",
    "    \n",
    "    # Next we replay the steps in the pipeline to make a prediction\n",
    "    z = model.intercept_ + model.coef_[0][0] * tf.transform(X)\n",
    "    return 1 / (1 + np.exp(-z)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaulate our logistic function for our test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic(regressor, predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these in hand lets generate some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "# Some aluminium values to predict from\n",
    "al_compositions = pandas.DataFrame(\n",
    "    {'test_al2o3_values': np.linspace(0.1, 3)}\n",
    ")\n",
    "\n",
    "# An offset to stop everything plotting on top of everything else\n",
    "offset = 0.02\n",
    "\n",
    "# shows predictions given contents\n",
    "predictions = regressor.predict(al_compositions)\n",
    "ax.plot(al_compositions, predictions + offset, '.', alpha=0.7, label='predicted (+ offset)')  \n",
    "\n",
    "# shows measured values plus jitter\n",
    "jitter = np.random.normal(scale=0.01, size=len(df))\n",
    "ax.plot(df['AL2O3'], df['is_ore'] + jitter - offset, '.', alpha=0.1, label='measured (+ jitter - offset)')\n",
    "\n",
    "# shows logistic function fitted from regressor\n",
    "ax.plot(al_compositions, logistic(regressor, al_compositions), '--', label='fitted logistic function')\n",
    "\n",
    "# Generate the logistic curve showing the location of \n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "ax.legend()\n",
    "ax.set_title('Logistic regression with scikit-learn')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this using one of the other variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring model performance\n",
    "\n",
    "We don't get everything right! How can we get a feeling for the model performance? What are some of the issues that we might need to take into account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train on just the training set, predict on the test set and see how we do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pandas.DataFrame({\n",
    "    'AL2O3': X_test['AL2O3'],\n",
    "    'is_ore_actual': y_test,\n",
    "    'is_ore_predicted': y_predict,\n",
    "    'count': 1\n",
    "})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the number of false positives and false negatives using pivot_table from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = results.pivot_table(values='count', index='is_ore_actual', columns='is_ore_predicted', aggfunc='sum')\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.heatmap(confusion, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can unstack the array into true and false negatives and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can convert these values to fractions of the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_neg, false_neg, true_pos, false_pos = confusion.unstack() / confusion.unstack().sum()\n",
    "true_neg, false_neg, true_pos, false_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When are true positives and false positives important?\n",
    "\n",
    "## Threshold\n",
    "\n",
    "We haven't done anything with the threshold yet - how should we pick the value for this?\n",
    "\n",
    "We've already got a confusion matrix - we can take the ratio of the true_positive vs the false_positive rates and compare the two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.diag(confusion)\n",
    "incorrect = np.diag(np.roll(confusion, 1, axis=1))\n",
    "correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct = correct.sum()\n",
    "total_incorrect = incorrect.sum()\n",
    "total_correct, total_incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot this for each threshold. We need a way of adjusting the class weights in the model. Scikit-learn doesn't let you specify a threshold directly but "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with_class_threshold(threshold):\n",
    "    \"Fit a logistic regression to get an ROC value for a given threshold\"\n",
    "    # Transform our threshold into class weights\n",
    "    class_weights = {True: threshold, False: 1 - threshold}\n",
    "    \n",
    "    # Make a regressor\n",
    "    regressor = pipeline.Pipeline([\n",
    "        ('transform', preprocessing.FunctionTransformer(np.log, validate=True)),\n",
    "        ('model', linear_model.LogisticRegression(class_weight=class_weights))\n",
    "    ])\n",
    "    \n",
    "    # Fit it\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make some predictions, see how we did\n",
    "    results = pandas.DataFrame({\n",
    "        'AL2O3': X_test['AL2O3'],\n",
    "        'is_ore_actual': y_test,\n",
    "        'is_ore_predicted': regressor.predict(X_test),\n",
    "        'count': 1\n",
    "    })\n",
    "    confusion = results.pivot_table(\n",
    "        values='count', \n",
    "        index='is_ore_actual', \n",
    "        columns='is_ore_predicted', \n",
    "        aggfunc='sum')\n",
    "    true_neg, false_neg, true_pos, false_pos = confusion.unstack()\n",
    "    correct = np.diag(confusion)\n",
    "    incorrect = np.diag(np.roll(confusion, 1, axis=1))\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'total_correct': correct.sum(), \n",
    "        'total_incorrect': incorrect.sum(), \n",
    "        'true_negative': true_neg,\n",
    "        'false_negative': false_neg,\n",
    "        'true_positive': true_pos,\n",
    "        'false_positive': false_pos\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate results using our metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_with_class_threshold(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_with_class_threshold(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate over all our thresholds and see what does the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pandas.DataFrame.from_records(\n",
    "    [fit_with_class_threshold(t) for t in np.linspace(0.1, 0.9)],\n",
    "    index='threshold'\n",
    ")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll generate a few plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(y=['total_correct', 'total_incorrect'])\n",
    "results.plot(y=['false_negative', 'true_negative'])\n",
    "results.plot(y=['false_positive', 'true_positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension - modelling with statsmodels\n",
    "\n",
    "For what it's worth we can also generate these using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from numpy import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to handle preprocessing ourselves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant\n",
    "\n",
    "def preprocess(x):\n",
    "    \"Our preprocessing pipeline for Al2O3\"\n",
    "    return add_constant(np.log(x)) # add_constant adds an intercept to the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels uses stats jargon \n",
    "- endog -> endogenous variable -> y\n",
    "- exog -> exogenous variable -> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog = df.is_ore\n",
    "exog = preprocess(df['AL2O3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model is pretty similar though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(endog, exog)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels does a bit more statistical testing/automated confidence intervals for us at the cost of having to manage crossvalidation etc ourselves. Depending on what you're trying to achieve this could be a viable way to go.\n",
    "\n",
    "As before we can immediately make some predictions - statsmodels gives us the value of the logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(results.params, preprocess(test_al_values))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare to scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.predict(test_al_values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the logistic values get slightly different answers here - probably down to the solver used under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' statsmodels:', model.predict(results.params, preprocess(test_al_values)))\n",
    "print('scikit-learn:', logistic(regressor, test_al_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate the same plot again though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "# Some aluminium values to predict from\n",
    "al_compositions = np.linspace(0.1, 3)\n",
    "\n",
    "# An offset to stop everything plotting on top of everything else\n",
    "offset = 0.02\n",
    "\n",
    "# shows predictions given contents\n",
    "predictions = model.predict(results.params, preprocess(al_compositions)) > 0.5\n",
    "ax.plot(al_compositions, predictions + offset, '.', alpha=0.7, label='predicted (+ offset)')  \n",
    "\n",
    "# shows measured values plus jitter\n",
    "jitter = np.random.normal(scale=0.01, size=len(df))\n",
    "ax.plot(df['AL2O3'], df['is_ore'] + jitter - offset, '.', alpha=0.1, label='measured (+ jitter - offset)')\n",
    "\n",
    "# shows logistic function fitted from regressor\n",
    "ax.plot(al_compositions, model.predict(results.params, preprocess(al_compositions)), '--', label='fitted logistic function')\n",
    "\n",
    "# Generate the logistic curve showing the location of \n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "ax.legend()\n",
    "ax.set_title('Logistic regression with statsmodels')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
